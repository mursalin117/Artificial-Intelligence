{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac95bd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 21:37:01.258495: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-20 21:37:01.445602: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-20 21:37:01.445622: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-20 21:37:02.477055: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-20 21:37:02.477170: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-20 21:37:02.477181: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "# import SciPy as scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814e2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "\n",
    "train_path = './Assignment-3/dataset/training/'\n",
    "test_path = './Assignment-3/dataset/testing/'\n",
    "val_path = './Assignment-3/dataset/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623d5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for folder in os.listdir(train_path):\n",
    "    sub_path = train_path + '/' + folder\n",
    "    for img in os.listdir(sub_path):\n",
    "        img_path = sub_path + '/' + img\n",
    "        img = cv.imread(img_path, 1)\n",
    "        img = cv.resize(img, img_size)\n",
    "#         print(img.shape)\n",
    "#         break\n",
    "        x_train.append(img)\n",
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1785487",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for folder in os.listdir(test_path):\n",
    "    sub_path = train_path + '/' + folder\n",
    "    for img in os.listdir(sub_path):\n",
    "        img_path = sub_path + '/' + img\n",
    "        img = cv.imread(img_path, 1)\n",
    "        img = cv.resize(img, img_size)\n",
    "        x_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f968f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = []\n",
    "for folder in os.listdir(val_path):\n",
    "    sub_path = train_path + '/' + folder\n",
    "    for img in os.listdir(sub_path):\n",
    "        img_path = sub_path + '/' + img\n",
    "        img = cv.imread(img_path, 1)\n",
    "        img = cv.resize(img, img_size)\n",
    "        x_val.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f328a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(x_train)\n",
    "test_x = np.array(x_test)\n",
    "val_x = np.array(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984b5e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x / 255.0\n",
    "test_x = test_x / 255.0\n",
    "val_x = val_x / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1efe6945",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1.0 / 255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0 / 255)\n",
    "val_dtagen = ImageDataGenerator(rescale = 1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b10369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 468 images belonging to 2 classes.\n",
      "Found 26 images belonging to 2 classes.\n",
      "Found 26 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory(train_path, target_size = img_size, batch_size = 32, class_mode = 'binary')\n",
    "test_set = train_datagen.flow_from_directory(test_path, target_size = img_size, batch_size = 32, class_mode = 'binary')\n",
    "val_set = train_datagen.flow_from_directory(val_path, target_size = img_size, batch_size = 32, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c7fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_set.classes\n",
    "test_y = test_set.classes\n",
    "val_y = val_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d28eb802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 222, 222, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 220, 220, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 110, 110, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 774400)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                12390416  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,429,713\n",
      "Trainable params: 12,429,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(224, 224, 3), filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.build(input_shape = (100, 224, 224, 1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a0930d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer=\"adam\",\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b7d78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)\n",
    "#Early stopping to avoid overfitting of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f801e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.4829"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 468\n  y sizes: 26\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fit the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;43;03m#     callbacks=[early_stop],\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/data_adapter.py:1848\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1842\u001b[0m         label,\n\u001b[1;32m   1843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1844\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1845\u001b[0m         ),\n\u001b[1;32m   1846\u001b[0m     )\n\u001b[1;32m   1847\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1848\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 468\n  y sizes: 26\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history=model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    validation_data=(test_x,test_y),\n",
    "    epochs=30,\n",
    "#     callbacks=[early_stop],\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9f2de21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 110s 7s/step - loss: 3.2551e-07 - accuracy: 1.0000 - val_loss: 3.6393e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 112s 7s/step - loss: 3.1144e-07 - accuracy: 1.0000 - val_loss: 3.4846e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 107s 7s/step - loss: 2.9766e-07 - accuracy: 1.0000 - val_loss: 3.3473e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 108s 7s/step - loss: 2.8480e-07 - accuracy: 1.0000 - val_loss: 3.2009e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 111s 7s/step - loss: 2.7258e-07 - accuracy: 1.0000 - val_loss: 3.0622e-07 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 111s 7s/step - loss: 2.6012e-07 - accuracy: 1.0000 - val_loss: 2.9395e-07 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 117s 8s/step - loss: 2.4866e-07 - accuracy: 1.0000 - val_loss: 2.8193e-07 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 109s 7s/step - loss: 2.3845e-07 - accuracy: 1.0000 - val_loss: 2.6954e-07 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 112s 7s/step - loss: 2.2860e-07 - accuracy: 1.0000 - val_loss: 2.5885e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 111s 7s/step - loss: 2.1875e-07 - accuracy: 1.0000 - val_loss: 2.4788e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_set,\n",
    "#     samples_per_epoch=234,\n",
    "    epochs=10,\n",
    "    validation_data=val_set #,\n",
    "#     nb_val_samples=13\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adc32fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 2.3498e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3498419920997549e-07, 1.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d606c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
